---
title: Evaluation of Hospitalization Forecasters 2024-2025
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: |
  This notebook is a template for evaluating hospitalization forecasters. It
  relies on the script get_scores.R from the same directory.
output:
  html_document:
    code_folding: hide
params:
  forecaster_set: 1
editor_options:
  chunk_output_type: console
---

$$\\[.4in]$$

```{r echo=FALSE}
# Package installation
knitr::opts_chunk$set(
    fig.align = "center",
    message = FALSE,
    warning = FALSE,
    cache = TRUE
)
```

```{r}
library(aws.s3)
library(data.table)
library(dplyr)
library(DT)
library(ggplot2)
library(plotly)
library(readr)
library(stringr)
library(scoringutils)
library(tidyr)
```

### Forecaster Name To Parameter Mapping

```{r}
source(here::here("scripts", "flu_hosp_explore.R"))
datatable(forecaster_parameter_combinations_[[1]])
datatable(forecaster_parameter_combinations_[[2]])
datatable(forecaster_parameter_combinations_[[3]])
datatable(forecaster_parameter_combinations_[[4]])
datatable(forecaster_parameter_combinations_[[5]])
```

### Retrieving Forecast Data

The forecasts are expected to have the following columns:

- `ahead`: The number of days ahead the forecast is made
- `geo_value`: The geographic unit of the forecast
- `forecast_date`: The date the forecast was made
- `forecaster`: The name of the forecaster
- `target_end_date`: The date the forecast is predicting
- `actual`: The actual value of the target
- `wis`: The weighted interval score
- `ae`: The absolute error
- `cov_80`: The 80% coverage
- `data_source`: The data source of the forecast
- `signal`: The signal of the forecast
- `incidence_period`: The period of the forecast

```{r}
# Local forecaster scores (if targets actually worked)
# tar_df <- targets::tar_manifest()
# local_scores <- tar_df %>%
#     filter(str_detect(name, "score_")) %>%
#     pull(name) %>%
#     map(~ tibble(forecaster = str_remove(.x, "score_"), tar_read_raw(.x))) %>%
#     bind_rows() %>%
# forecast_dates <- local_scores %>%
#     pull(forecast_date) %>%
#     unique()

# Load local forecaster scores
s3load(object = "flu_2023_forecaster_scores_1.rds", bucket = "forecasting-team-data")
local_scores <- flu_2023_forecaster_scores_1 %>%
    # This is a correction for the fact that we forecast on Wednesdays, but labeled
    # the forecasts as if they were made on the following Saturday.
    mutate(forecast_date = forecast_date + 3, target_end_date = target_end_date + 3)
forecast_dates <- local_scores %>%
    pull(forecast_date) %>%
    unique()

# Load ensemble and baseline data for comparison
# s3load("flusight_scores_2022", bucket = "forecasting-team-data")
s3load("flusight_scores_2023", bucket = "forecasting-team-data")

location_data <- read_csv("https://raw.githubusercontent.com/cmu-delphi/covidcast-indicators/refs/heads/main/_delphi_utils_python/delphi_utils/data/2020/state_codes_table.csv") %>%
    select(state_code, state_id)
flusight_scores_2023_transformed <- flusight_scores_2023 %>%
    filter(
        model %in% c("FluSight-baseline", "FluSight-ensemble"),
        reference_date %in% forecast_dates
    ) %>%
    as.data.table() %>%
    add_coverage(by = c("model", "reference_date", "target_end_date", "location"), ranges = c(80)) %>%
    summarize_scores(by = c("model", "reference_date", "target_end_date", "location")) %>%
    as_tibble() %>%
    left_join(location_data, by = c("location" = "state_code")) %>%
    mutate(location = state_id) %>%
    select(
        model,
        geo_value = location,
        forecast_date = reference_date,
        target_end_date,
        wis = interval_score,
        ae = ae_median,
        coverage_80
    )

scores <- local_scores %>%
    bind_rows(flusight_scores_2023_transformed) %>%
    select(forecaster = model, geo_value, forecast_date, target_end_date, wis, ae, coverage_80) %>%
    mutate(ahead = as.numeric(target_end_date - forecast_date))

forecasters <- scores %>%
    pull(forecaster) %>%
    unique()
aheads <- scores %>%
    pull(ahead) %>%
    unique()

Mean <- function(x) mean(x, na.rm = TRUE)
GeoMean <- function(x, offset = 0) exp(Mean(log(x + offset)))
```

**The target forecast dates are:** <br/> `r forecast_dates`

**The template will compile data of the following forecasters:** <br/> `r forecasters`.

$$\\[.07in]$$

### Weighted Interval Score (relative to baseline) and 80% Coverage {.tabset}

Score all forecasters relative to the COVIDhub-baseline, aggregating across
geos with geometric mean.

#### WIS by Forecast Date

```{r}
base_forecaster_name <- "FluSight-baseline"
var <- "wis"
id_cols <- c("forecaster", "forecast_date", "ahead")

df <- scores %>%
    select(all_of(c(id_cols, var))) %>%
    drop_na(forecast_date, !!sym(var)) %>%
    summarize(!!var := GeoMean(!!sym(var)), .by = all_of(id_cols)) %>%
    # TODO: Filter out negative aheads for now.
    filter(ahead >= 0)

if (df %>% filter(forecaster == base_forecaster_name & near(!!sym(var), 0)) %>% nrow() > 0) {
    warning("scale_by_forecaster will divide by zero in column ", var)
}

normalized_df <- df %>%
    select(all_of(c(id_cols, var))) %>%
    pivot_wider(names_from = forecaster, names_prefix = var, values_from = !!sym(var)) %>%
    mutate(across(starts_with(var), ~ .x / !!sym(paste0(var, base_forecaster_name)))) %>%
    pivot_longer(cols = starts_with(var), names_to = "forecaster", values_to = var) %>%
    mutate(forecaster = stringr::str_remove(forecaster, var)) %>%
    filter(forecaster != base_forecaster_name)

facets.label <- str_glue("{aheads} days ahead")
names(facets.label) <- aheads
subtitle <- sprintf(
    "Forecasts made over %s to %s",
    format(min(forecast_dates), "%B %d, %Y"),
    format(max(forecast_dates), "%B %d, %Y")
)
p <- ggplot(normalized_df, aes(x = forecast_date, y = !!sym(var))) +
    geom_line(aes(color = forecaster, group = forecaster)) +
    geom_point(aes(color = forecaster, group = forecaster)) +
    facet_grid(rows = vars(ahead)) +
    facet_wrap(~ahead, nrow = 4, labeller = labeller(ahead = facets.label)) +
    scale_y_log10() +
    scale_color_viridis_d() +
    guides(color = guide_legend(ncol = 2)) +
    labs(title = subtitle, x = "Forecast Dates", y = "Geometric Mean WIS")

ggplotly(p, tooltip = "text", height = 800, width = 1000) %>%
    layout(hoverlabel = list(bgcolor = "white"))
```

#### WIS by Ahead

```{r}
base_forecaster_name <- "FluSight-baseline"
var <- "wis"
id_cols <- c("forecaster", "ahead")

df <- scores %>%
    select(all_of(c(id_cols, var))) %>%
    drop_na(!!sym(var)) %>%
    summarize(!!var := GeoMean(!!sym(var)), .by = all_of(id_cols)) %>%
    # TODO: Filter out negative aheads for now.
    filter(ahead >= 0)

if (df %>% filter(forecaster == base_forecaster_name & near(!!sym(var), 0)) %>% nrow() > 0) {
    warning("scale_by_forecaster will divide by zero in column ", var)
}

normalized_df <- df %>%
    select(all_of(c(id_cols, var))) %>%
    pivot_wider(names_from = forecaster, names_prefix = var, values_from = !!sym(var)) %>%
    mutate(across(starts_with(var), ~ .x / !!sym(paste0(var, base_forecaster_name)))) %>%
    pivot_longer(cols = starts_with(var), names_to = "forecaster", values_to = var) %>%
    mutate(forecaster = stringr::str_remove(forecaster, var)) %>%
    filter(forecaster != base_forecaster_name)

subtitle <- sprintf(
    "Forecasts made over %s to %s",
    format(min(forecast_dates), "%B %d, %Y"),
    format(max(forecast_dates), "%B %d, %Y")
)
p <- ggplot(normalized_df, aes(x = ahead, y = !!sym(var))) +
    geom_line(aes(color = forecaster, group = forecaster)) +
    geom_point(aes(color = forecaster, group = forecaster)) +
    scale_y_log10() +
    scale_color_viridis_d() +
    guides(color = guide_legend(ncol = 2)) +
    labs(title = subtitle, x = "Days ahead", y = "Geometric Mean WIS")

ggplotly(p, tooltip = "text", height = 800, width = 1000) %>%
    layout(hoverlabel = list(bgcolor = "white"))
```

#### % Coverage by Forecast Date

```{r}
base_forecaster_name <- "FluSight-baseline"
var <- "coverage_80"
id_cols <- c("forecaster", "forecast_date", "ahead")

df <- scores %>%
    select(all_of(c(id_cols, var))) %>%
    drop_na(forecast_date, !!sym(var)) %>%
    summarize(!!var := Mean(!!sym(var)), .by = all_of(id_cols)) %>%
    # TODO: Filter out negative aheads for now.
    filter(ahead >= 0)

if (df %>% filter(forecaster == base_forecaster_name & near(!!sym(var), 0)) %>% nrow() > 0) {
    warning("scale_by_forecaster will divide by zero in column ", var)
}

normalized_df <- df %>%
    select(all_of(c(id_cols, var))) %>%
    pivot_wider(names_from = forecaster, names_prefix = var, values_from = !!sym(var)) %>%
    mutate(across(starts_with(var), ~ .x / !!sym(paste0(var, base_forecaster_name)))) %>%
    pivot_longer(cols = starts_with(var), names_to = "forecaster", values_to = var) %>%
    mutate(forecaster = stringr::str_remove(forecaster, var)) %>%
    filter(forecaster != base_forecaster_name)

facets.label <- str_glue("{aheads} days ahead")
names(facets.label) <- aheads
subtitle <- sprintf(
    "Forecasts made over %s to %s",
    format(min(forecast_dates), "%B %d, %Y"),
    format(max(forecast_dates), "%B %d, %Y")
)
p <- ggplot(normalized_df, aes(x = forecast_date, y = !!sym(var))) +
    geom_line(aes(color = forecaster, group = forecaster)) +
    geom_point(aes(color = forecaster, group = forecaster)) +
    facet_grid(rows = vars(ahead)) +
    facet_wrap(~ahead, nrow = 4, labeller = labeller(ahead = facets.label)) +
    scale_y_log10() +
    scale_color_viridis_d() +
    guides(color = guide_legend(ncol = 2)) +
    labs(title = subtitle, x = "Forecast Dates", y = "Mean 80% Coverage")
p

ggplotly(p, tooltip = "text", height = 800, width = 1000) %>%
    layout(hoverlabel = list(bgcolor = "white"))
```

#### % Coverage by Ahead

```{r}
base_forecaster_name <- "FluSight-baseline"
var <- "coverage_80"
id_cols <- c("forecaster", "ahead")

df <- scores %>%
    select(all_of(c(id_cols, var))) %>%
    drop_na(!!sym(var)) %>%
    summarize(!!var := Mean(!!sym(var)), .by = all_of(id_cols)) %>%
    # TODO: Filter out negative aheads for now.
    filter(ahead >= 0)

if (df %>% filter(forecaster == base_forecaster_name & near(!!sym(var), 0)) %>% nrow() > 0) {
    warning("scale_by_forecaster will divide by zero in column ", var)
}

normalized_df <- df %>%
    select(all_of(c(id_cols, var))) %>%
    pivot_wider(names_from = forecaster, names_prefix = var, values_from = !!sym(var)) %>%
    mutate(across(starts_with(var), ~ .x / !!sym(paste0(var, base_forecaster_name)))) %>%
    pivot_longer(cols = starts_with(var), names_to = "forecaster", values_to = var) %>%
    mutate(forecaster = stringr::str_remove(forecaster, var)) %>%
    filter(forecaster != base_forecaster_name)

subtitle <- sprintf(
    "Forecasts made over %s to %s",
    format(min(forecast_dates), "%B %d, %Y"),
    format(max(forecast_dates), "%B %d, %Y")
)
p <- ggplot(normalized_df, aes(x = ahead, y = !!sym(var))) +
    geom_line(aes(color = forecaster, group = forecaster)) +
    geom_point(aes(color = forecaster, group = forecaster)) +
    scale_y_log10() +
    scale_color_viridis_d() +
    guides(color = guide_legend(ncol = 2)) +
    labs(title = subtitle, x = "Days ahead", y = "Mean 80% Coverage")
p

ggplotly(p, tooltip = "text", height = 800, width = 1000) %>%
    layout(hoverlabel = list(bgcolor = "white"))
```

### Fan plots

```{r}
# TODO: Need to upload the forecast data and then copy the plotting code from the vignette.
# local_forecasts <- tar_df %>%
#     filter(str_detect(name, "forecast_")) %>%
#     pull(name) %>%
#     map(~ tibble(forecaster = str_remove(.x, "forecast_"), tar_read_raw(.x))) %>%
#     bind_rows() %>%
#     # This is a correction for the fact that we forecast on Wednesdays, but labeled
#     # the forecasts as if they were made on the following Saturday.
#     mutate(forecast_date = forecast_date + 3, target_end_date = target_end_date + 3)

s3load(object = "flu_2023_forecaster_scores_1.rds", bucket = "forecasting-team-data")
flu_2023_forecaster_scores_1 %>%
    # This is a correction for the fact that we forecast on Wednesdays, but labeled
    # the forecasts as if they were made on the following Saturday.
    mutate(forecast_date = forecast_date + 3, target_end_date = target_end_date + 3)
```
