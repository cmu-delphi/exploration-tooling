---
talk-title: "Forecasting Season 2024/25 Summary"
talk-short-title: "Season 2025"
talk-subtitle: "State level quantile forecasting of flu and covid hospitalizations"
author: "Dmitry Shemetov & David Weber"
other-authors: ""
repo-address: ""
date: "2025-05-22"
format:
  revealjs:
    theme: [default, themer.scss]
    css: tachyons-minimal.css
    logo: "gfx/delphi.jpg"
    chalkboard: true
    width: 1280
    height: 720
    html-math-method: mathjax
    slide-number: true
    fig-format: svg
    fig-align: center
    fig-width: 5.33
    fig-height: 3
    scrollable: false
    history: false
    link-external-icon: true
    link-external-newwindow: true
    code-overflow: wrap
    lang: en-CA
    footer: "{{< meta talk-short-title >}} --- {{< meta repo-address >}}"
    output-file: "season_summary_2025_presentation.html"
---

<!-- Set any of the above to "" to omit them -->

<!-- The below is _titleslide.qmd from before -->

---
---

\DeclareMathOperator*{\minimize}{minimize}

```{r setup}
#| include: false
primary <- "#a8201a"
secondary <- "#f9c80e"
tertiary <- "#2a76dd"
fourth_colour <- "#311847"
library(epiprocess)
suppressMessages(library(tidyverse))
x <- archive_cases_dv_subset
x_latest <- epix_as_of(x, max_version = max(x$DT$version))
self_max = max(x$DT$version)
versions = seq(as.Date("2020-06-01"), self_max - 1, by = "1 month")
snapshots_all <- map_dfr(versions, function(v) {
  epix_as_of(x, max_version = v) %>% mutate(version = v)}) %>%
  bind_rows(x_latest %>% mutate(version = self_max)) %>%
  mutate(latest = version == self_max)
snapshots <- snapshots_all %>%
  filter(geo_value %in% c("ca", "fl"))
```

```{r}
#| include: false
#| label: cover-art
snapshots_all |>
  arrange(geo_value, version, time_value) |>
  # filter(!latest) |>
  ggplot(aes(x = time_value, y = percent_cli)) +
  geom_line(
    aes(color = factor(version), group = interaction(geo_value, version))
  ) +
  # geom_vline(aes(color = factor(version), xintercept = version), lty = 3,
  #           size = 0.5) +
  scale_x_date(minor_breaks = "month", labels = NULL) +
  labs(x = "", y = "") +
  theme_void() +
  coord_cartesian(xlim = as.Date(c("2020-10-01", NA)), ylim = c(-5, NA)) +
  scale_color_viridis_d(option = "B", end = .8) +
  theme(legend.position = "none", panel.background = element_blank()) +
  geom_line(
    data = snapshots %>% filter(latest),
    aes(x = time_value, y = percent_cli, group = geo_value),
    inherit.aes = FALSE, color = primary)
```

::: flex
::: w-30

:::
::: w-70

## {{< meta talk-title >}} {background-image="gfx/cover-art-1.svg" background-position="bottom"}

### {{< meta talk-subtitle >}}

<br>

#### {{< meta author >}}
{{< meta other-authors >}}

{{< meta date >}}
:::
:::

<!-- The above is _titleslide.qmd from before -->

```{r data_setup, include=FALSE}
library(tidyverse)
library(epidatr)
library(epipredict)
library(epidatasets)
library(ggridges)
theme_set(theme_bw())
knitr::opts_chunk$set(
  fig.align = "center",
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  dev = "png"
)
ggplot2::theme_set(ggplot2::theme_bw())
suppressPackageStartupMessages(source(here::here("R", "load_all.R")))
# Define aggregation functions
Mean <- function(x) mean(x, na.rm = TRUE)
GeoMean <- function(x, offset = 0) exp(Mean(log(x + offset)))
our_forecasters <- c("linear", "windowed_seasonal", "windowed_seasonal_nssp", "climate_base", "climate_geo_agged", "climate_linear", "ensemble_windowed", "retro_submission", "CMU-TimeSeries", "seasonal_nssp_latest", "ensemble_mix")
flu_scores <-
  qs2::qs_read(here::here("flu_hosp_prod", "objects", "scores")) %>%
  mutate(forecaster = case_match(
           forecaster,
    "windowed_seasonal_extra_sources" ~ "windowed_seasonal_nssp",
    "ensemble_linclim_windowed_seasonal" ~ "retro_submission",
    "ens_ar_only" ~ "ensemble_windowed",
    .default = forecaster
    )) %>%
  mutate(our_forecaster = forecaster %in% our_forecasters)
flu_forecasts <- qs2::qs_read(here::here("flu_hosp_prod", "objects", "joined_forecasts_and_ensembles"))
flu_forecasts$forecaster %<>% case_match(
    "windowed_seasonal_extra_sources" ~ "windowed_seasonal_nssp",
    "ensemble_linclim_windowed_seasonal" ~ "retro_submission",
    "ens_ar_only" ~ "ensemble_windowed",
    .default = flu_forecasts$forecaster
    )
forecast_dates <- qs2::qs_read(here::here("flu_hosp_prod", "objects", "forecast_dates"))
covid_scores <- qs2::qs_read(here::here("covid_hosp_prod", "objects", "scores")) %>%
  mutate(forecaster = case_match(
           forecaster,
    "windowed_seasonal_extra_sources" ~ "windowed_seasonal_nssp",
    "ensemble_linclim_windowed_seasonal" ~ "retro_submission",
    "ens_ar_only" ~ "ensemble_windowed",
    .default = forecaster
    )) %>%
  mutate(our_forecaster = forecaster %in% our_forecasters)
covid_forecasts <- qs2::qs_read(here::here("covid_hosp_prod", "objects", "joined_forecasts_and_ensembles")) %>% ungroup()
covid_forecasts$forecaster %<>% case_match(
    "windowed_seasonal_extra_sources" ~ "windowed_seasonal_nssp",
    "ensemble_linclim_windowed_seasonal" ~ "retro_submission",
    "ens_ar_only" ~ "ensemble_windowed",
    .default = covid_forecasts$forecaster
    )

forecast_week <- flu_scores$forecast_date %>% unique()
forecast_weeks_to_plot <- c(seq.Date(min(forecast_week), max(forecast_week), by = 3*7), as.Date("2025-01-18"), as.Date("2025-02-01"))
forecast_weeks_to_plot %in% (flu_scores$forecast_date %>% unique())
forecast_weeks_to_plot %in% (covid_scores$forecast_date %>% unique())
```

# Major Forecasting Challenges

- **non-stationarity** - varying vaccination rates, strains, mobility, superspreader events, etc.
- **large seasonal variation (flu)** - season start, duration, and peak size vary
- **lack of seasonal component (covid)** - seasonal pattern in the data is weak (post-pandemic)
- **bad data quality** - initial observations are incomplete, regular reporting delays, errors, etc.
- **few seasons to train on** - NHSN data starts in 2020, the first two seasons are excluded because they were anomalous due to the pandemic, so effectively only 2 seasons of data are available for training

# The Data

## Recent Seasons Data: Flu

```{r flu_archive, fig.width = 20, fig.height = 10, fig.align = "center"}
nhsn_archive_flu <- qs2::qs_read(here::here("flu_hosp_prod", "objects", "nhsn_archive_data"))
nhsn_latest <- nhsn_archive_flu %>%
  epix_as_of_current() %>%
  # Cut out the tiny fraction of 2019/20 data (there's like 58 data points)
  filter(time_value >= "2020-10-01") %>%
  add_season_info() %>%
  filter(geo_value %nin% c("as", "gu", "mp", "vi"))
ggplot(nhsn_latest, aes(x = season_week, y = value, color = season, size = season)) +
  geom_line() +
  facet_wrap(~geo_value, scale = "free") +
  theme(legend.text = element_text(size = 12)) +
  scale_size_manual(values = c(rep(0.5,5), 1))
```

::: {.notes}
Here we see the 2024/25 season in pink.
It's the worst season in 15 years and very different from the previous 2 seasons.
Before that, the 2020/21 and the 2021/22 seasons are essentially negligible due to the pandemic (so we've dropped them).

[SciAm article with some speculation on why](https://www.scientificamerican.com/article/why-this-years-flu-season-is-the-worst-in-more-than-a-decade/).
- Late start -> less protection + 2nd wave
- different strain (H3N2 H1N1)
- decreased vaccination (not that low)
- lower levels of immunity from decreased exposure

This bears out somewhat in NSSP, but it is not as extreme an increase, so it may be a change in reporting.
:::

## Recent Seasons Data: Covid

```{r covid_archive, fig.width = 20, fig.height = 10, fig.align = "center"}
nhsn_archive_covid <- qs2::qs_read(here::here("covid_hosp_prod", "objects", "nhsn_archive_data"))
nhsn_latest_covid <- nhsn_archive_covid %>%
  epix_as_of_current() %>%
  add_season_info() %>%
  filter(geo_value %nin% c("as", "gu", "mp", "vi"), season %nin% c("2019/20", "2020/21", "2021/22"))
ggplot(nhsn_latest_covid, aes(x = season_week, y = value, color = season, size = season)) +
  geom_line() +
  facet_wrap(~geo_value, scale = "free") +
  theme(legend.text = element_text(size = 12)) +
  scale_size_manual(values = c(rep(0.5, 2), 1))
```

::: {.notes}
Here we've dropped the 2020 through 2022 seasons because they absolutely swamp the past 3 years.
Even so, this year is frequently without a season at all depending on the geo (for instance, see CA and FL and TX); part of the reason for this is the late summer wave, which is not visible in this data.
:::

## Data Revisions: Flu

```{r flu_revision}
nhsn_archive_flu$time_type <- "day"
revision_sum <- nhsn_archive_flu %>% epiprocess::revision_analysis(value, min_waiting_period = NULL)
av_re_spread <- revision_sum$revision_behavior %>%
  group_by(geo_value) %>%
  summarize(rel_spread = mean(rel_spread, na.rm = TRUE)) %>%
  arrange(desc(rel_spread)) %>%
  filter(geo_value %nin% c("vi", "as", "gu"))
nhsn_filtered <- nhsn_archive_flu %>%
  filter(geo_value %in% av_re_spread$geo_value[1:18]) %>%
  filter(time_value >= "2024-11-19")
nhsn_filtered$DT %<>%
  mutate(geo_value = factor(geo_value, levels = av_re_spread$geo_value[1:18]))
```

```{r flu_revision_plot, fig.width = 20, fig.height = 8, fig.align = "center"}
autoplot(nhsn_filtered, "value") + facet_wrap(~geo_value, ncol = 3, scales = "free") + theme(strip.text.x = element_text(size = 8)) +
  labs(title = "States with the largest mean revision")
```

::: {.notes}
Here we see the revision behavior in the states with the largest mean revision.
Note that some revisions are massive: NH, AZ, MN, MO.
:::

## Data Revisions: Covid

```{r covid_revision}
nhsn_archive_covid$time_type <- "day"
revision_sum <- nhsn_archive_covid %>% epiprocess::revision_analysis(value, min_waiting_period = NULL)
av_re_spread <- revision_sum$revision_behavior %>%
  group_by(geo_value) %>%
  summarize(rel_spread = mean(rel_spread, na.rm = TRUE)) %>%
  arrange(desc(rel_spread)) %>%
  filter(geo_value %nin% c("vi", "as", "gu"))
nhsn_filtered <- nhsn_archive_covid %>%
  filter(geo_value %in% av_re_spread$geo_value[1:18]) %>%
  filter(time_value >= "2024-11-19")
nhsn_filtered$DT %<>%
  mutate(geo_value = factor(geo_value, levels = av_re_spread$geo_value[1:18]))
```

```{r Covid_revision_plot, fig.width = 20, fig.height = 8, fig.align = "center"}
autoplot(nhsn_filtered, "value") + facet_wrap(~geo_value, ncol = 3, scales = "free") + theme(strip.text.x = element_text(size = 8)) +
  labs(title = "States with the largest mean revision")
```

::: {.notes}
Here we see the revision behavior in the states with the largest mean revision.
Note that some revisions are massive: DC, AZ, MN, MO, HI.
:::

# Models

## Our Models: Simplest

::: {.notes}
In order of increasing complexity/usage
:::

- `linear`: linearly extrapolate the last 4 weeks
- `climate_base`: a climatological model, quantiles estimated from a 7 week period centered on the `target_date`'s season week from historical data for that geo
- `climate_geo`: a climatological model, like `climate_base` but converts to rates, and then creates quantiles using all geos.
- `climate_linear`: a weighted ensemble of the climatological and linear
```{r climate_weight_plot, fig.width = 20, fig.height = 3, fig.align = "center"}
weights <-
  make_ahead_weights(-1:3) %>%
  left_join(
    make_quantile_weights(covidhub_probs()),
    by = c("forecast_family"),
    relationship = "many-to-many"
  ) %>%
  mutate(weight = weight.x * weight.y) %>%
  select(forecast_family, quantile, ahead, weight)
weights %>%
  filter(forecast_family == "climate") %>%
  ggplot(aes(y = factor(ahead), x = factor(quantile), fill = weight)) +
  geom_tile() +
  scale_fill_viridis_c(limits = c(0,1))
```

## Our Models: Autoregressive

- `windowed_seasonal`: an AR model where the training data is taken from a window 4 weeks before and after the training
  + The model is roughly $x_t = x_{t-7} + x_{t-14}$, where $x$ is the scaled NHSN data (along with ILI+ and FluSURV) and $t$ is the target date in days.
  + Covid predicted this on rates data
  + For flu, this model also uses ILI+ data and fluSURV, with the forecasts done on variance-stabilized, scaled, and centered data, on a per-geo-source basis.
    - the variance stabilization is a 4th root
    - the scaling is by the difference between the 5th and 95th quantiles
    - the centering is so that the median is zero

::: {.notes}
This "training window" approach to handling seasonality gave a large improvement to the model score over the base AR model.
The augmented data sources also improved the model score.
We did not see much improvement from adding more lags or tweaking the whitening settings.
:::

## Our Models: Autoregressive with Exogenous Predictors

- `windowed_seasonal_nssp`: like `windowed_seasonal` without the data scaling, and using `nssp` (emergency department visits) as an exogenous predictor (same lags).
  + The model is roughly $x_t = x_{t-7} + x_{t-14} + y_{t-7} + y_{t-14}$, where $x$ is the scaled NHSN data (along with ILI+ and FluSURV) and $y$ is the NSSP data, and $t$ is the target date in days.

::: {.notes}
This exogenous predictor gave the largest improvement to the model score out of Google Symptoms and NWSS.
:::

## Timeline of models used {.smaller}
:::: {.columns}
::: {.column width = "50%"}
### Flu Model {.smaller}
- `2024-11-21` initial forecast, straight average of `climate_base`, `climate_geo` and `linear`
- `2024-11-27` `climate_linear` ensemble instead of average (2 weeks)
- `2024-12-11` introduce `windowed_seasonal` to ensemble (5 weeks)
- `2025-01-15` introduce `windowed_seasonal_nssp` to ensemble
- Final model ensembles `windowed_seasonal` (which uses ILI+ and FluSURV), `windowed_seasonal_nssp` (which doesn't), and `climate_linear`
:::

::: {.column width = "50%"}
### Covid Model {.smaller}
- `2024-11-21` initial forecast, straight average of `climate_base`, `climate_geo` and `linear`
- `2024-11-27` `climate_linear` ensemble instead of average (9 weeks)
- `2025-01-29` `windowed_seasonal_nssp` introduced to ensemble
- `2025-02-19` forecast using only `windowed_seasonal_nssp`
- Final model uses only `windowed_seasonal_nssp`, except for states without `nssp`, where it ensembles `windowed_seasonal` and `climate_linear`
:::

::::

::: {.notes}
The takeaway here is mostly that we changed the model a lot as the season progressed.
:::

# Flu Scores
## Flu Scores: WIS {.smaller}

```{r computing_phase}
flu_archive <- qs2::qs_read(here::here("flu_hosp_prod", "objects", "nhsn_archive_data"))
flu_current <- flu_archive %>%
  epix_as_of_current() %>%
  filter(geo_value %nin% c("as", "gu", "mp", "vi"))
flu_max <- flu_current %>% group_by(geo_value) %>% summarize(max_value = max(value))
compute_peak_season <- function(data_current, threshold = 0.5, start_of_year = as.Date("2024-11-01")) {
  season_length <- data_current %>% pull(time_value) %>% max() - start_of_year
  data_current %>%
    filter(time_value > start_of_year) %>%
    group_by(geo_value) %>%
    mutate(max_val = max(value)) %>%
    filter(value >= threshold * max_val) %>%
    summarize(first_above = min(time_value), last_above = max(time_value)) %>%
    mutate(
      duration = last_above - first_above,
      rel_duration = as.integer(duration) / as.integer(season_length))
}
classify_phase <- function(time_value, first_above, last_above, rel_duration, threshold) {
  case_when(
    rel_duration > threshold ~ "flat",
    time_value < first_above ~ "increasing",
    time_value > last_above ~ "decreasing",
    .default = "peak"
  ) %>% factor(levels = c("increasing", "peak", "decreasing", "flat"))
}
covid_flat_threshold <- 0.6
flu_flat_threshold <- 0.9
flu_within_max <- compute_peak_season(flu_current)

sanity_check_classifying <- flu_current %>%
  left_join(flu_within_max, by = "geo_value") %>%
  mutate(phase = classify_phase(time_value, first_above, last_above, rel_duration, covid_flat_threshold)) %>%
  group_by(geo_value) %>%
  distinct(phase)
repo_forecasters <- c(setdiff(unique(flu_scores$forecaster), our_forecasters), "CMU-TimeSeries")
flu_score_summary <- flu_scores %>%
  left_join(state_census, by = join_by(geo_value == abbr)) %>%
  group_by(forecaster) %>%
  mutate(
    min_wis = min(wis[wis > 1e-5]),
    min_ae = min(ae_median[ae_median > 1e-5])
  ) %>%
  summarize(
    mean_wis = round(Mean(wis), 2),
    wis_sd = round(sd(wis), 2),
    pop_norm_wis = round(Mean(wis *1e5/pop), 2),
    pop_norm_wis_sd = round(sd(wis * 1e5/pop), 2),
    geo_wis = round(GeoMean(wis, min_wis), 2),
    #nWISzero = sum(wis < 1e-5),
    mean_ae = round(Mean(ae_median), 2),
    ae_sd = round(sd(ae_median), 2),
    pop_norm_ae = round(Mean(ae_median*1e5/pop), 2),
    pop_norm_ae_sd = round(sd(ae_median * 1e5/pop), 2),
    geo_ae = round(GeoMean(ae_median, min_ae), 2),
    #nAEzero = sum(ae_median < 1e-5),
    mean_cov_50 = round(Mean(interval_coverage_50), 2),
    mean_cov_90 = round(Mean(interval_coverage_90), 2),
    n = n()
  ) %>%
  arrange(mean_wis)
```

```{r flu_datatable, fig.height = 60, fig.width = 12, echo=FALSE}
wis_score_order <- flu_score_summary %>% pull(forecaster)
pop_score_order <- flu_score_summary %>% arrange(pop_norm_wis) %>% pull(forecaster)
flu_wis_summary <- flu_score_summary %>%
  filter(forecaster %nin% c("seasonal_nssp_latest")) %>%
  select(forecaster, mean_wis, wis_sd, pop_norm_wis, pop_norm_wis_sd, mean_cov_50, mean_cov_90, n)
flu_wis_data_only <- flu_wis_summary %>% select(-forecaster, -n)
datatable(
  flu_wis_summary,
  fillContainer = FALSE,
  options = list(
    initComplete = htmlwidgets::JS(
          "function(settings, json) {",
          paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
          "}"),
    pageLength = 25
  )
) %>%
  formatStyle("forecaster", target = c("cell"),
              fontWeight = styleEqual(repo_forecasters, rep("900", length(repo_forecasters))),
              textDecoration = styleEqual("CMU-TimeSeries", "underline")) %>%
  formatStyle(
    "mean_wis",
    background = styleColorBar(c(0, max(flu_wis_summary$mean_wis)), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  ) %>%
  formatStyle(
    "pop_norm_wis",
    background = styleColorBar(c(0, max(flu_wis_summary$pop_norm_wis)), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  )
```

::: {.notes}
The external forecasters are in bold.
Our submitted forecasts are "CMU-TimeSeries".
The rest are our component models (as they exist now).

Takeaways:
- `windowed_seasonal_nssp` attains very low WIS
- `climate_linear` performs surprisingly well given its simplicity
- TODO: more commentary
:::

## Flu Scores: Absolute Error {.smaller}
```{r flu_scores_ae}
flu_ae_summary <- flu_score_summary %>%
  arrange(mean_ae) %>%
  filter(forecaster %nin% c("seasonal_nssp_latest")) %>%
  select(forecaster, mean_ae, ae_sd, pop_norm_ae, pop_norm_ae_sd, mean_cov_50, mean_cov_90, n) %>%
  arrange(mean_ae)
datatable(
    flu_ae_summary,
    fillContainer = FALSE,
    options = list(
      initComplete = htmlwidgets::JS(
          "function(settings, json) {",
          paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
          "}"),
      pageLength = 25
    )
  ) %>%
  formatStyle("forecaster", target = c("cell"),
              fontWeight = styleEqual(repo_forecasters, rep("900", length(repo_forecasters))),
              textDecoration = styleEqual("CMU-TimeSeries", "underline")) %>%
  formatStyle(
    "mean_ae",
    background = styleColorBar(c(0, max(flu_ae_summary$mean_ae)), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  ) %>%
  formatStyle(
    "pop_norm_ae",
    background = styleColorBar(c(0, max(flu_ae_summary$pop_norm_ae)), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  )
```

## Flu Scores: WIS Rate Histogram

::: {.notes}
These scores are rates rather than counts, and color gives population.
Note there's an implied fat tail in the distribution of scores.
Overall, the distributions of scores are very similar.

In the increasing phase, CMU-TimeSeries has a smaller left tail, but a more concentrated middle, and smaller right tail, so this doesn't show up in the aggregate.
In the peak phase, CMU-TimeSeries has a thinner left tail (meaning we have fewer cases where we're dead on), which is enough to show up in the aggregate.
The decreasing phase is about the same for the compared models.
:::

```{r flu_score_histogram, fig.height = 13, fig.width = 25, echo=FALSE}
data <- flu_scores %>%
  filter(forecaster %in% c("PSI-PROF", "FluSight-ensemble", "climate_base", "CMU-TimeSeries", "UMass-flusion"))  %>%
  left_join(flu_within_max, by = "geo_value") %>%
  left_join(state_census, by = join_by(geo_value == abbr)) %>%
  mutate(wis = wis * 1e5/pop) %>%
  mutate(pop = factor(pop)) %>%
  mutate(forecaster = factor(forecaster, levels = wis_score_order)) %>%
  group_by(forecaster) %>%
  mutate(phase = classify_phase(target_end_date, first_above, last_above, rel_duration, covid_flat_threshold))

ggplot(data, aes(x = wis, y = forecaster, fill = forecaster)) +
  geom_density_ridges(scale = 3, alpha = 0.7) +
  scale_y_discrete(expand = c(0, 0)) +     # will generally have to set the `expand` option
  scale_x_continuous(expand = c(0, 0)) +   # for both axes to remove unneeded padding
  scale_fill_brewer(palette = 4) +
  coord_cartesian(clip = "off") + # to avoid clipping of the very top of the top ridgeline
  theme_ridges() +
  facet_wrap(~phase) +
  labs(title = "Wis score histogram") +
  ylab("phase") +
  xlab("wis, population normalized") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  theme(legend.position = "none")
```

## Flu Scores: Phase
::: {.notes}
We classify the season into three phases: increasing, peak, and decreasing.
Increasing is before the first time the value exceeds a threshold.
Decreasing is the last time the value dips below the threshold.
Peak is between these two.
The threshold is chosen at 50% of the max value.

Note that our WIS/AE is in the top 5, but everyone's score is quite similar and washed out.
We performed well in the increasing/decreasing phases, but most of our error came in the peak phase.
:::

```{r flu_phase}
phase_scores <-
  flu_scores %>%
  filter(forecaster %nin% c("seasonal_nssp_latest")) %>%
  left_join(flu_within_max, by = "geo_value") %>%
  mutate(phase = classify_phase(target_end_date, first_above, last_above, rel_duration, covid_flat_threshold)) %>%
  group_by(forecaster, phase) %>%
  summarize(
    wis_sd = round(sd(wis, na.rm = TRUE), 2),
    ae_sd = round(sd(ae_median, na.rm = TRUE), 2),
    across(c(wis, ae_median, interval_coverage_90), \(x) round(Mean(x), 2)),
    n = n(),
    our_forecaster = first(our_forecaster),
    .groups = "drop"
  )
sketch <- htmltools::withTags(table(
  class = 'display',
  style = "font-size: 11px;",
  thead(
    tr(
      th(colspan = 2, "forecaster"),
      th(colspan = 2, 'increasing'),
      th(colspan = 2, 'peak'),
      th(colspan = 2, 'decreasing')
    ),
    tr(
      list(th("peak_wis_rank"), th("name"),
           lapply(rep(c('wis', 'sd'), 3), th)
           )
    )
  )
))
phase_scores_wider <- phase_scores %>%
  select(forecaster, phase, wis, wis_sd, our_forecaster) %>%
  pivot_wider(names_from = phase, values_from = c(wis, wis_sd))
wis_max <- phase_scores_wider %>% select(wis_increasing, wis_peak, wis_decreasing) %>% max()
phase_scores_wider %>%
  select(forecaster, wis_increasing, wis_sd_increasing, wis_peak, wis_sd_peak, wis_decreasing, wis_sd_decreasing) %>%
  arrange(wis_peak) %>%
  datatable(
    fillContainer = FALSE,
    options = list(
      initComplete = htmlwidgets::JS(
          "function(settings, json) {",
          paste0("$(this.api().table().container()).css({'font-size': '", "11pt", "'});"),
          "}"),
      pageLength = 25
    ),
    container = sketch
  ) %>%
  formatStyle("forecaster", target = c("cell"),
              fontWeight = styleEqual(repo_forecasters, rep("900", length(repo_forecasters))),
              textDecoration = styleEqual("CMU-TimeSeries", "underline")) %>%
  formatStyle(
    "wis_increasing",
    background = styleColorBar(c(0, wis_max), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  ) %>%
  formatStyle(
    "wis_peak",
    background = styleColorBar(c(0, wis_max), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  ) %>%
  formatStyle(
    "wis_decreasing",
    background = styleColorBar(c(0, wis_max), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  )

```


## Flu: Sample Forecasts
::: {.notes}
80% CI
We're plotting the 80% CI along with the median.
The locations were chosen based on the scores to have a sample of large and small states with large and small (population normalized) WIS.
We've scaled so everything is in rates per 100k so that it's easier to actually compare; even so the peak value varies drastically.
Forecasters we've produced are blue, while forecasters from other teams are red.
They are ordered by `mean_wis` score, best to worst.
:::

```{r flu_plot_sample_forecast, fig.height = 7, fig.width = 16, echo=FALSE}
plot_geos <- c("ca", "dc", "pa", "hi", "tx")
filtered_flu_forecasts <- flu_forecasts %>%
  filter(quantile %in% c(0.1, 0.5, 0.9), geo_value %in% plot_geos) %>%
  filter(forecaster %in% c("UMass-flusion", "CMU-TimeSeries", "PSI-PROF", "windowed_seasonal"))
# flu_forecasts %>% distinct(forecaster) %>% print(n = 30)
#filtered_flu_forecasts %>% filter(geo_value == "pa") %>% arrange(forecast_date) %>% drop_na(value)

flu_forecast_plt <-
  filtered_flu_forecasts %>%
  filter(forecast_date %in% forecast_weeks_to_plot) %>%
  mutate(forecaster = factor(forecaster, levels = wis_score_order)) %>%
  mutate(our_forecaster = factor(forecaster %in% our_forecasters, levels = c(TRUE, FALSE))) %>%
  left_join(state_census, by = join_by(geo_value == abbr)) %>%
  mutate(value = value * 1e5/ pop) %>%
  pivot_wider(names_from = quantile, values_from = value) %>%
  ggplot(aes(x = target_end_date)) +
  geom_ribbon(aes(ymin = `0.1`, ymax = `0.9`, color = our_forecaster, fill = our_forecaster, group = forecast_date), alpha = 0.5) +
  geom_line(aes(y = `0.5`, color = our_forecaster, group = forecast_date)) +
  geom_line(
    data = flu_current %>%
      filter(time_value > "2024-11-01", geo_value %in% plot_geos) %>%
      left_join(state_census, by = join_by(geo_value == abbr)) %>%
      mutate(value = value * 1e5/ pop),
    aes(x = time_value, y = value)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(forecaster ~ geo_value, scale = "free") +
  theme(legend.position = "none") +
  scale_x_date(breaks = "1 month", date_labels = "%b") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 16)) +
  ylab("rates")

flu_forecast_plt
```


## Flu: Forecasting on latest
::: {.notes}
The point is to demonstrate the upper bound of what accurate nowcasting would get us.
named `seasonal_nssp_latest` compare with `windowed_seasonal_nssp`. Generally outperforms all other models by a good margin.
:::

```{r flu_phase_two}
phase_scores <-
  flu_scores %>%
  left_join(flu_within_max, by = "geo_value") %>%
  mutate(phase = classify_phase(target_end_date, first_above, last_above, rel_duration, covid_flat_threshold)) %>%
  group_by(forecaster, phase) %>%
  summarize(
    wis_sd = round(sd(wis, na.rm = TRUE), 2),
    ae_sd = round(sd(ae_median, na.rm = TRUE), 2),
    across(c(wis, ae_median, interval_coverage_90), \(x) round(Mean(x), 2)),
    n = n(),
    our_forecaster = first(our_forecaster),
    .groups = "drop"
  )
sketch <- htmltools::withTags(table(
  class = 'display',
  style = "font-size: 11px;",
  thead(
    tr(
      th(colspan = 2, "forecaster"),
      th(colspan = 2, 'increasing'),
      th(colspan = 2, 'peak'),
      th(colspan = 2, 'decreasing')
    ),
    tr(
      list(th("peak_wis_rank"), th("name"),
           lapply(rep(c('wis', 'sd'), 3), th)
           )
    )
  )
))
phase_scores_wider <- phase_scores %>%
  select(forecaster, phase, wis, wis_sd, our_forecaster) %>%
  pivot_wider(names_from = phase, values_from = c(wis, wis_sd))
wis_max <- phase_scores_wider %>% select(wis_increasing, wis_peak, wis_decreasing) %>% max()
phase_scores_wider %>%
  select(forecaster, wis_increasing, wis_sd_increasing, wis_peak, wis_sd_peak, wis_decreasing, wis_sd_decreasing) %>%
  arrange(wis_peak) %>%
  datatable(
    fillContainer = FALSE,
    options = list(
      initComplete = htmlwidgets::JS(
          "function(settings, json) {",
          paste0("$(this.api().table().container()).css({'font-size': '", "11pt", "'});"),
          "}"),
      pageLength = 25
    ),
    container = sketch
  ) %>%
  formatStyle("forecaster", target = c("cell"),
              fontWeight = styleEqual(repo_forecasters, rep("900", length(repo_forecasters))),
              textDecoration = styleEqual("CMU-TimeSeries", "underline")) %>%
  formatStyle(
    "wis_increasing",
    background = styleColorBar(c(0, wis_max), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  ) %>%
  formatStyle(
    "wis_peak",
    background = styleColorBar(c(0, wis_max), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  ) %>%
  formatStyle(
    "wis_decreasing",
    background = styleColorBar(c(0, wis_max), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  )
```

# Covid Scores
## Covid Scores: WIS {.smaller}
::: {.notes}
`CMU-TimeSeries` did significantly worse; a large part of this is poor performance on literally the first week
:::
```{r computing_phase_covid}
covid_archive <- qs2::qs_read(here::here("covid_hosp_prod", "objects", "nhsn_archive_data"))
covid_current <- covid_archive %>%
  epix_as_of_current() %>%
  filter(geo_value %nin% c("as", "gu", "mp", "vi"))
covid_max <- covid_current %>% group_by(geo_value) %>% summarize(max_value = max(value))
covid_within_max <- compute_peak_season(covid_current)

sanity_check_classifying <- covid_current %>%
  left_join(covid_within_max, by = "geo_value") %>%
  mutate(phase = classify_phase(time_value, first_above, last_above, rel_duration, covid_flat_threshold)) %>%
  group_by(geo_value) %>%
  distinct(phase)
repo_forecasters <- c(setdiff(unique(covid_scores$forecaster), our_forecasters), "CMU-TimeSeries")
covid_score_summary <- covid_scores %>%
  left_join(state_census, by = join_by(geo_value == abbr)) %>%
  group_by(forecaster) %>%
  mutate(
    min_wis = min(wis[wis > 1e-5]),
    min_ae = min(ae_median[ae_median > 1e-5])
  ) %>%
  summarize(
    mean_wis = round(Mean(wis), 2),
    wis_sd = round(sd(wis), 2),
    pop_norm_wis = round(Mean(wis *1e5/pop), 2),
    pop_norm_wis_sd = round(sd(wis * 1e5/pop), 2),
    geo_wis = round(GeoMean(wis, min_wis), 2),
    #nWISzero = sum(wis < 1e-5),
    mean_ae = round(Mean(ae_median), 2),
    ae_sd = round(sd(ae_median), 2),
    pop_norm_ae = round(Mean(ae_median*1e5/pop), 2),
    pop_norm_ae_sd = round(sd(ae_median * 1e5/pop), 2),
    geo_ae = round(GeoMean(ae_median, min_ae), 2),
    #nAEzero = sum(ae_median < 1e-5),
    mean_cov_50 = round(Mean(interval_coverage_50), 2),
    mean_cov_90 = round(Mean(interval_coverage_90), 2),
    n = n()
  ) %>%
  arrange(mean_wis)
```

```{r covid_datatable, fig.height = 60, fig.width = 12, echo=FALSE}
wis_score_order <- covid_score_summary %>% pull(forecaster)
pop_score_order <- covid_score_summary %>% arrange(pop_norm_wis) %>% pull(forecaster)
covid_wis_summary <-
covid_score_summary %>%
  filter(forecaster %nin% c("seasonal_nssp_latest")) %>%
  select(forecaster, mean_wis, wis_sd, pop_norm_wis, pop_norm_wis_sd, mean_cov_50, mean_cov_90, n)

  datatable(
    covid_wis_summary,
    fillContainer = FALSE,
    options = list(
      initComplete = htmlwidgets::JS(
          "function(settings, json) {",
          paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
          "}"),
      pageLength = 25
    )
  ) %>%
  formatStyle("forecaster", target = c("cell"),
              fontWeight = styleEqual(repo_forecasters, rep("900", length(repo_forecasters))),
              textDecoration = styleEqual("CMU-TimeSeries", "underline")) %>%
  formatStyle(
    "mean_wis",
    background = styleColorBar(c(0, max(flu_wis_summary$mean_wis)), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  ) %>%
  formatStyle(
    "pop_norm_wis",
    background = styleColorBar(c(0, max(flu_wis_summary$pop_norm_wis)), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  )
```

## Covid Scores: Absolute Error {.smaller}
```{r covid_scores_ae}
covid_ae_summary <- covid_score_summary %>%
  arrange(mean_ae) %>%
  filter(forecaster %nin% c("seasonal_nssp_latest")) %>%
  select(forecaster, mean_ae, ae_sd, pop_norm_ae, pop_norm_ae_sd, mean_cov_50, mean_cov_90, n)
  datatable(
    covid_ae_summary,
    fillContainer = FALSE,
    options = list(
      initComplete = htmlwidgets::JS(
          "function(settings, json) {",
          paste0("$(this.api().table().container()).css({'font-size': '", "10pt", "'});"),
          "}"),
      pageLength = 25
    )
  ) %>%
  formatStyle("forecaster", target = c("cell"),
              fontWeight = styleEqual(repo_forecasters, rep("900", length(repo_forecasters))),
              textDecoration = styleEqual("CMU-TimeSeries", "underline")) %>%
  formatStyle(
    "mean_ae",
    background = styleColorBar(c(0, max(covid_ae_summary$mean_ae)), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  ) %>%
  formatStyle(
    "pop_norm_ae",
    background = styleColorBar(c(0, max(covid_ae_summary$pop_norm_ae)), 'lightblue'),
    backgroundSize = '98% 88%',
    backgroundRepeat = 'no-repeat',
    backgroundPosition = 'center'
  )
```
## Coivd Scores: Aggregated By Forecast Date

```{r, fig.height = 6, fig.width = 12, echo=FALSE}
agg_covid <- covid_scores %>%
  filter(forecast_date > "2024-10-01") %>%
  filter(forecast_date != as.Date("2025-01-25")) %>%
  group_by(forecaster, forecast_date) %>%
  summarize(
    mean_wis = round(Mean(wis), 2),
    wis_sd = round(sd(wis), 2),
    geomean_wis = round(GeoMean(wis), 2),
    mean_ae = round(Mean(ae_median), 2),
    geomean_ae = round(GeoMean(ae_median), 2),
    mean_interval_coverage_90 = round(Mean(interval_coverage_90), 2),
  )

p <- ggplot(agg_covid, aes(x = forecast_date, y = mean_wis, color = forecaster)) +
  geom_line() +
  #geom_ribbon(aes(ymin = mean_wis - wis_sd, ymax = mean_wis + wis_sd, fill = forecaster), alpha = 0.1) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "Forecast Date", y = "Mean WIS")

style(ggplotly(p), visible = "legendonly", traces = c(1, 6, 8, 9, 10, 11, 12, 13, 14))
```


## Covid Scores: Wis Rate Histogram

::: {.notes}
These scores are rates rather than counts.

Note that again, the score distributions are very similar.
You can see where CMU-TimeSeries performed worse at the beginning of the season in the top left.
This was due to a naive use of the climatological baseline, which completely overestimated values in states that had no season.
:::

```{r covid_score_histogram, fig.height = 13, fig.width = 25, echo=FALSE}
data <- covid_scores %>%
  filter(forecaster %in% c("PSI-PROF", "CovidHub-ensemble", "climate_base", "CMU-TimeSeries", "UMass-ar6_pooled"))  %>%
  left_join(covid_within_max, by = "geo_value") %>%
  left_join(state_census, by = join_by(geo_value == abbr)) %>%
  mutate(wis = wis * 1e5/pop) %>%
  mutate(pop = factor(pop)) %>%
  mutate(forecaster = factor(forecaster, levels = wis_score_order)) %>%
  group_by(forecaster) %>%
  mutate(phase = classify_phase(target_end_date, first_above, last_above, rel_duration, covid_flat_threshold))

ggplot(data, aes(x = wis, y = forecaster, fill = forecaster)) +
  geom_density_ridges(scale = 3, alpha = 0.7) +
  scale_y_discrete(expand = c(0, 0)) +     # will generally have to set the `expand` option
  scale_x_continuous(expand = c(0, 0)) +   # for both axes to remove unneeded padding
  scale_fill_brewer(palette = 4) +
  coord_cartesian(clip = "off") + # to avoid clipping of the very top of the top ridgeline
  theme_ridges() +
  facet_wrap(~phase) +
  labs(title = "Wis score histogram") +
  ylab("phase") +
  xlab("wis, population normalized") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  theme(legend.position = "none")
```


## Covid Scores: Phase

```{r covid_phase}
phase_scores <-
  covid_scores %>%
  filter(forecaster %nin% c("seasonal_nssp_latest")) %>%
  left_join(covid_within_max, by = "geo_value") %>%
  mutate(phase = classify_phase(target_end_date, first_above, last_above, rel_duration, covid_flat_threshold)) %>%
  group_by(forecaster, phase) %>%
  summarize(
    wis_sd = round(sd(wis, na.rm = TRUE), 2),
    ae_sd = round(sd(ae_median, na.rm = TRUE), 2),
    across(c(wis, ae_median, interval_coverage_90), \(x) round(Mean(x), 2)),
    n = n(),
    our_forecaster = first(our_forecaster),
    .groups = "drop"
  )
sketch <- htmltools::withTags(table(
  class = 'display',
  style = "font-size: 11px;",
  thead(
    tr(
      th(colspan = 2, "forecaster"),
      th(colspan = 2, 'increasing'),
      th(colspan = 2, 'peak'),
      th(colspan = 2, 'decreasing')
    ),
    tr(
      list(th("peak_wis_rank"), th("name"),
           lapply(rep(c('wis', 'sd'), 3), th)
           )
    )
  )
))
phase_scores_wider <- phase_scores %>%
  select(forecaster, phase, wis, wis_sd, our_forecaster) %>%
  pivot_wider(names_from = phase, values_from = c(wis, wis_sd))
phase_scores_wider %>%
  select(forecaster, wis_increasing, wis_sd_increasing, wis_peak, wis_sd_peak, wis_decreasing, wis_sd_decreasing) %>%
  arrange(wis_peak) %>%
  datatable(
    fillContainer = FALSE,
    options = list(
      initComplete = htmlwidgets::JS(
          "function(settings, json) {",
          paste0("$(this.api().table().container()).css({'font-size': '", "11pt", "'});"),
          "}"),
      pageLength = 25
    ),
    container = sketch
  ) %>%
  formatStyle("forecaster", target = c("cell"),
              fontWeight = styleEqual(repo_forecasters, rep("900", length(repo_forecasters))),
              textDecoration = styleEqual("CMU-TimeSeries", "underline"))
```


## Covid: Sample Forecasts
::: {.notes}
80% CI
We're plotting the 80% CI along with the median.
The locations were chosen based on the scores to have a sample of large and small states with large and small (population normalized) WIS.
We've scaled so everything is in rates per 100k so that it's easier to actually compare; even so the peak value varies drastically.
Forecasters we've produced are blue, while forecasters from other teams are red.
They are ordered by `mean_wis` score, best to worst.
:::

```{r covid_plot_sample_forecast, fig.height = 7, fig.width = 12, echo=FALSE}
plot_geos <- c("ca", "dc", "pa", "hi", "tx")
filtered_covid_forecasts <- covid_forecasts %>%
  filter(quantile %in% c(0.1, 0.5, 0.9), geo_value %in% plot_geos) %>%
  filter(forecaster %in% c("UMass-covidsion", "CMU-TimeSeries", "PSI-PROF", "windowed_seasonal"))

covid_forecast_plt <-
  filtered_covid_forecasts %>%
  filter(forecast_date %in% forecast_weeks_to_plot) %>%
  mutate(forecaster = factor(forecaster, levels = wis_score_order)) %>%
  mutate(our_forecaster = factor(forecaster %in% our_forecasters, levels = c(TRUE, FALSE))) %>%
  left_join(state_census, by = join_by(geo_value == abbr)) %>%
  mutate(value = value * 1e5/ pop) %>%
  pivot_wider(names_from = quantile, values_from = value) %>%
  ggplot(aes(x = target_end_date)) +
  geom_ribbon(aes(ymin = `0.1`, ymax = `0.9`, color = our_forecaster, fill = our_forecaster, group = forecast_date), alpha = 0.5) +
  geom_line(aes(y = `0.5`, color = our_forecaster, group = forecast_date)) +
  geom_line(
    data = covid_current %>%
      filter(time_value > "2024-11-01", geo_value %in% plot_geos) %>%
      left_join(state_census, by = join_by(geo_value == abbr)) %>%
      mutate(value = value * 1e5/ pop),
    aes(x = time_value, y = value)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  facet_grid(forecaster ~ geo_value, scale = "free") +
  theme(legend.position = "none") +
  scale_x_date(breaks = "1 month", date_labels = "%b") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 16)) +
  ylab("rates")

ggplotly(covid_forecast_plt)
```

## Future Work

- Account for "always decreasing" behavior observed in nearly all forecasters (include external forecasters)
  - We've determined that this is due to data bias, so we need ways to mitigate that.
  - Possible solution is to attempt to split the data into phase components and fit a different model to each phase.
    (Was tried before, but didn't work as well as hoped; perhaps with a better phase definition it could be better?)
- Nowcasting, revision anticipation
- Forecasting at the city/county level for NSSP (metrocasting)
- Check evaluation robustness via data "fuzzing"
  - A way to mitigate over-weighting the performance of a forecaster on a single season
  - Possibilities include parametric boot with observational noise (additive and/or shifts) or leave-one-out training across seasons (e.g. leave 2023 out and train on 2022 and 2024)

## Final slide {.smaller}

### Thanks:

```{r qr-codes}
#| include: false
#| fig-format: png
# Code to generate QR codes to link to any external sources
qrdat <- function(text, ecl = c("L", "M", "Q", "H")) {
  x <- qrcode::qr_code(text, ecl)
  n <- nrow(x)
  s <- seq_len(n)
  tib <- tidyr::expand_grid(x = s, y = rev(s))
  tib$z <- c(x)
  tib
}
qr1 <- qrdat("https://cmu-delphi.github.io/epiprocess/")
qr2 <- qrdat("https://cmu-delphi.github.io/epipredict/")
ggplot(qr1, aes(x, y, fill = z)) +
  geom_raster() +
  ggtitle("{epiprocess}") +
  coord_equal(expand = FALSE) +
  scale_fill_manual(values = c("white", "black"), guide = "none") +
  theme_void(base_size = 18) +
  theme(plot.title = element_text(hjust = .5))
ggplot(qr2, aes(x, y, fill = z)) +
  geom_raster() +
  labs(title = "{epipredict}") +
  coord_equal(expand = FALSE) +
  scale_fill_manual(values = c("white", "black"), guide = "none") +
  theme_void(base_size = 18) +
  theme(plot.title = element_text(hjust = .5))
```

:::: {.columns}
::: {.column width="50%"}
- The whole [CMU Delphi Team](https://delphi.cmu.edu/about/team/) (across many institutions)
- Optum/UnitedHealthcare, Change Healthcare.
- Google, Facebook, Amazon Web Services.
- Quidel, SafeGraph, Qualtrics.
- Centers for Disease Control and Prevention.
- Council of State and Territorial Epidemiologists
:::

::: {.column width="50%"}

![](gfx/qr-epiprocess.png){width="300px"}
![](gfx/qr-epipredict.png){width="300px"}

:::

::::

::: {layout-row=1 fig-align="center"}
![](gfx/delphi.jpg){height="100px"}
![](gfx/berkeley.jpg){height="100px"}
![](gfx/cmu.jpg){height="100px"}
![](gfx/ubc.jpg){width="250px"}
![](gfx/usc.jpg){width="250px"}
![](gfx/stanford.jpg){width="250px"}
:::


# Appendix

## Scoring Metrics

:::: {.columns}
::: {.column width="50%"}

- Weighted interval score (WIS)
  - Discrete approximation to CRPS, which sums the colored area in the figure squared
- Absolute error (AE)
  - $|y_t - m|$ where $m$ is the median forecast
- 80% prediction interval coverage (80%PI)
  - Proportion of times the true value falls within the center 80%
:::
::: {.column width="50%"}

```{r, fig.width = 5, fig.height = 5}
df <- data.frame(x = seq(-1, 2, length.out = 3000))

# Calculate y values for both functions
df$y1 <- pnorm(df$x, mean = 0.5, sd = 0.25)  # Normal CDF
df$y2 <- ifelse(df$x >= 0.75, 1, 0)        # Step function

# Plot
ggplot(df, aes(x = x)) +
  # Plot the functions with color aesthetic
  geom_line(aes(y = y1, color = "CDF of forecast")) +
  geom_line(aes(y = y2, color = "Eventually observed value")) +
  # Add the ribbon between the functions
  geom_ribbon(aes(ymin = pmin(y1, y2), ymax = pmax(y1, y2), fill = "WIS ~ ∫(F(x) - I(x ≥ .75))²"),
              alpha = 0.3) +
  # Customize colors and fills
  scale_color_manual(name = "", values = c("CDF of forecast" = "red",
                                          "Eventually observed value" = "blue")) +
  scale_fill_manual(name = "", values = c("WIS ~ ∫(F(x) - I(x ≥ .75))²" = "red")) +
  # Add legend inside plot
  theme(legend.position = c(0.2, 0.8),  # Adjust these values to position the legend
        legend.background = element_rect(fill = "white"),
        legend.text = element_text(size = 6)) +
  labs(x = "x", y = "CDF", title = "WIS example") +
  theme(plot.title = element_text(hjust = 0.5))
```

:::
::::
